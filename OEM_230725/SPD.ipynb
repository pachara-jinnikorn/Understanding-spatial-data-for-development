{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTGkOTdOpBll"
   },
   "source": [
    "# OpenEarhMap Semantinc Segmentation\n",
    "\n",
    "This demo code demonstrates training and testing of UNet-EfficientNet-B4 for the OpenEarthMap dataset (https://open-earth-map.org/). This demo code is based on the work from the \"segmentation_models.pytorch\" repository by qubvel, available at: https://github.com/qubvel/segmentation_models.pytorch. We extend our sincere appreciation to the original author for their invaluable contributions to the field of semantic segmentation and for providing this open-source implementation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWiUctcOpBlo"
   },
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17923,
     "status": "ok",
     "timestamp": 1690293306384,
     "user": {
      "displayName": "Naoto Yokoya",
      "userId": "10610249095566174844"
     },
     "user_tz": -540
    },
    "id": "gQdFTlpypBlp",
    "outputId": "755dab4f-711e-4438-c42c-a1a5cbbeb130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rasterio in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: affine in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in c:\\users\\lucky\\appdata\\roaming\\python\\python312\\site-packages (from rasterio) (24.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rasterio) (2024.2.2)\n",
      "Requirement already satisfied: click>=4.0 in c:\\users\\lucky\\appdata\\roaming\\python\\python312\\site-packages (from rasterio) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rasterio) (1.26.4)\n",
      "Requirement already satisfied: click-plugins in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rasterio) (3.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lucky\\appdata\\roaming\\python\\python312\\site-packages (from click>=4.0->rasterio) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pretrainedmodels in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.7.4)\n",
      "Requirement already satisfied: torch in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pretrainedmodels) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pretrainedmodels) (0.21.0+cu118)\n",
      "Requirement already satisfied: munch in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pretrainedmodels) (4.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lucky\\appdata\\roaming\\python\\python312\\site-packages (from pretrainedmodels) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->pretrainedmodels) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\lucky\\appdata\\roaming\\python\\python312\\site-packages (from torch->pretrainedmodels) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->pretrainedmodels) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->pretrainedmodels) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lucky\\appdata\\roaming\\python\\python312\\site-packages (from torch->pretrainedmodels) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->pretrainedmodels) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->pretrainedmodels) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch->pretrainedmodels) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision->pretrainedmodels) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision->pretrainedmodels) (11.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lucky\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->pretrainedmodels) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->pretrainedmodels) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: efficientnet_pytorch in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from efficientnet_pytorch) (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->efficientnet_pytorch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\lucky\\appdata\\roaming\\python\\python312\\site-packages (from torch->efficientnet_pytorch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->efficientnet_pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->efficientnet_pytorch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lucky\\appdata\\roaming\\python\\python312\\site-packages (from torch->efficientnet_pytorch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->efficientnet_pytorch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->efficientnet_pytorch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch->efficientnet_pytorch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: timm in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.13)\n",
      "Requirement already satisfied: torch in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (0.21.0+cu118)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (0.23.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (0.5.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lucky\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub->timm) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (23.2)\n",
      "Requirement already satisfied: requests in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\lucky\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub->timm) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lucky\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision->timm) (11.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lucky\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lucky\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rasterio \n",
    "%pip install pretrainedmodels \n",
    "%pip install efficientnet_pytorch \n",
    "%pip install timm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4elx5iipBlq"
   },
   "source": [
    "### Import\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 8920,
     "status": "ok",
     "timestamp": 1690293451338,
     "user": {
      "displayName": "Naoto Yokoya",
      "userId": "10610249095566174844"
     },
     "user_tz": -540
    },
    "id": "zhMDpFqZpBlr"
   },
   "outputs": [],
   "source": [
    "import sys #library à¸—à¸µà¹ˆà¸ˆà¸±à¸”à¹€à¸•à¸£à¸µà¸¢à¸¡à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¹à¸¥à¸°à¸•à¸±à¸§à¹à¸›à¸£à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹€à¸žà¸·à¹ˆà¸­à¸ˆà¸±à¸”à¸à¸²à¸£à¸à¸±à¸šà¸ªà¹ˆà¸§à¸™à¸•à¹ˆà¸²à¸‡à¹†à¸‚à¸­à¸‡ Python Runtime Environment\n",
    "sys.path.append(r'C:\\Users\\lucky\\Desktop\\Understanding-spatial-data-for-development\\OEM_230725\\SPD.ipynb')  # Correct path to the directory containing source.py\n",
    "import os #à¸™à¸³à¹€à¸‚à¹‰à¸² module OS à¸¡à¸²à¹ƒà¸™à¹‚à¸„à¹‰à¸”à¸ à¸²à¸©à¸² Python\n",
    "import time #à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸•à¹ˆà¸²à¸‡à¹† à¸¡à¸²à¸à¸¡à¸²à¸¢à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¹€à¸§à¸¥à¸²\n",
    "import numpy as np # library à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¸„à¸³à¸™à¸§à¸™à¸—à¸²à¸‡à¸„à¸“à¸´à¸•à¸¨à¸²à¸ªà¸•à¸£à¹Œà¹ƒà¸™à¸ à¸²à¸©à¸² Python\n",
    "import torch #library for use Machine Learning\n",
    "import torch.nn as nn #Neural Network à¸„à¸·à¸­ Layer à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²\n",
    "from torch.utils.data import DataLoader #à¸„à¸·à¸­ Dataset object à¹à¸¥à¸°à¸¥à¸´à¸ªà¸•à¹Œà¸‚à¸­à¸‡à¸ˆà¸³à¸™à¸§à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸ˆà¸°à¹à¸šà¹ˆà¸‡\n",
    "import source  # Ensure 'source.py' is in the 'final_finish' directory\n",
    "import segmentation_models_pytorch as smp #\n",
    "import glob\n",
    "import torchvision.transforms.functional as TF\n",
    "import math\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Os768d4EpBlr"
   },
   "source": [
    "### Define main parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1690293575342,
     "user": {
      "displayName": "Naoto Yokoya",
      "userId": "10610249095566174844"
     },
     "user_tz": -540
    },
    "id": "fOj5_N4apBlr",
    "outputId": "fcfc3a93-3030-4614-ecdf-ba54ca866b6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs   : 5\n",
      "Number of classes  : 9\n",
      "Batch size         : 4\n",
      "Device             : cuda\n"
     ]
    }
   ],
   "source": [
    "OEM_ROOT = r\"C:\\Users\\lucky\\Desktop\\Understanding-spatial-data-for-development\\OEM_230725\\data\\OpenEarthMap_Demo\"\n",
    "OEM_DATA_DIR = os.path.join(OEM_ROOT, 'train_val')\n",
    "TEST_DIR = OEM_ROOT+'test/'\n",
    "TRAIN_LIST = os.path.join(OEM_ROOT, \"train.txt\")\n",
    "VAL_LIST = os.path.join(OEM_ROOT, \"val.txt\")\n",
    "WEIGHT_DIR = r\"C:\\Users\\lucky\\Desktop\\Understanding-spatial-data-for-development\\OEM_230725\\weight\" # path to save weights\n",
    "OUT_DIR = r\"C:\\Users\\lucky\\Desktop\\Understanding-spatial-data-for-development\\OEM_230725\\result\" # path to save prediction images\n",
    "os.makedirs(WEIGHT_DIR, exist_ok=True)\n",
    "test_large = OEM_ROOT+'/N35.675E139.725.tif'\n",
    "\n",
    "seed = 0\n",
    "learning_rate = 0.0001\n",
    "batch_size = 4\n",
    "n_epochs = 5\n",
    "classes = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "n_classes = len(classes)+1\n",
    "classes_wt = np.ones([n_classes], dtype=np.float32)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Number of epochs   :\", n_epochs)\n",
    "print(\"Number of classes  :\", n_classes)\n",
    "print(\"Batch size         :\", batch_size)\n",
    "print(\"Device             :\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCETH4-PpBls"
   },
   "source": [
    "### Prepare training and validation file lists\n",
    "\n",
    "In this demo for Google Colab, we use only two regions, i.e., Tokyo and Kyoto for training. To train with the full set, please download the OpenEarthMap dataset from https://zenodo.org/record/7223446. Note for xBD data preparation is available at https://github.com/bao18/open_earth_map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1690293462748,
     "user": {
      "displayName": "Naoto Yokoya",
      "userId": "10610249095566174844"
     },
     "user_tz": -540
    },
    "id": "gn8aGxUvpBls",
    "outputId": "82f2abed-3597-4e31-abbf-a0c0c3d40804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples      : 10000\n",
      "Training samples   : 20\n",
      "Validation samples : 10\n"
     ]
    }
   ],
   "source": [
    "img_pths = [f for f in Path(OEM_DATA_DIR).rglob(\"*.png\") if \"labels\" in str(f)]\n",
    "train_pths = [str(f) for f in img_pths if f.name in np.loadtxt(TRAIN_LIST, dtype=str)]\n",
    "val_pths = [str(f) for f in img_pths if f.name in np.loadtxt(VAL_LIST, dtype=str)]\n",
    "\n",
    "print(\"Total samples      :\", len(img_pths))\n",
    "print(\"Training samples   :\", len(train_pths))\n",
    "print(\"Validation samples :\", len(val_pths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-uFSOcgpBlt"
   },
   "source": [
    "### Define training and validation dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1690293465821,
     "user": {
      "displayName": "Naoto Yokoya",
      "userId": "10610249095566174844"
     },
     "user_tz": -540
    },
    "id": "DkjJGjCOpBlt"
   },
   "outputs": [],
   "source": [
    "trainset = source.dataset.Dataset(train_pths, classes=classes, size=512, train=True)\n",
    "validset = source.dataset.Dataset(val_pths, classes=classes, train=False)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(validset, batch_size=batch_size, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aR9cFGaspBlt"
   },
   "source": [
    "### Setup network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5902,
     "status": "ok",
     "timestamp": 1690293476037,
     "user": {
      "displayName": "Naoto Yokoya",
      "userId": "10610249095566174844"
     },
     "user_tz": -540
    },
    "id": "oTIQto7LpBlt",
    "outputId": "dceb44e7-4f97-4865-c153-aa65fe099f75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\n",
      "Model output name  : u-efficientnet-b4_s0_CELoss\n",
      "Number of parameters:  20304278\n"
     ]
    }
   ],
   "source": [
    "network = smp.Unet(\n",
    "    classes=n_classes,\n",
    "    activation=None,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    encoder_name=\"efficientnet-b4\",\n",
    "    decoder_attention_type=\"scse\",\n",
    ")\n",
    "\n",
    "# count parameters\n",
    "params = 0\n",
    "for p in network.parameters():\n",
    "    if p.requires_grad:\n",
    "        params += p.numel()\n",
    "\n",
    "criterion = source.losses.CEWithLogitsLoss(weights=classes_wt)\n",
    "criterion_name = 'CE'\n",
    "metric = source.metrics.IoU2()\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
    "network_fout = f\"{network.name}_s{seed}_{criterion.name}\"\n",
    "OUT_DIR += network_fout # path to save prediction images\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Model output name  :\", network_fout)\n",
    "print(\"Number of parameters: \", params)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Number of GPUs :\", torch.cuda.device_count())\n",
    "    network = torch.nn.DataParallel(network)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [dict(params=network.module.parameters(), lr=learning_rate)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2lQx068bQwo"
   },
   "source": [
    "### Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1690293490628,
     "user": {
      "displayName": "Naoto Yokoya",
      "userId": "10610249095566174844"
     },
     "user_tz": -540
    },
    "id": "yTJFfnmspBlu"
   },
   "outputs": [],
   "source": [
    "class_rgb = {\n",
    "    \"Bareland\": [128, 0, 0],\n",
    "    \"Grass\": [0, 255, 36],\n",
    "    \"Pavement\": [148, 148, 148],\n",
    "    \"Road\": [255, 255, 255],\n",
    "    \"Tree\": [34, 97, 38],\n",
    "    \"Water\": [0, 69, 255],\n",
    "    \"Cropland\": [75, 181, 73],\n",
    "    \"buildings\": [222, 31, 7],\n",
    "}\n",
    "\n",
    "class_gray = {\n",
    "    \"Bareland\": 1,\n",
    "    \"Grass\": 2,\n",
    "    \"Pavement\": 3,\n",
    "    \"Road\": 4,\n",
    "    \"Tree\": 5,\n",
    "    \"Water\": 6,\n",
    "    \"Cropland\": 7,\n",
    "    \"buildings\": 8,\n",
    "}\n",
    "\n",
    "def label2rgb(a):\n",
    "    \"\"\"\n",
    "    a: labels (HxW)\n",
    "    \"\"\"\n",
    "    out = np.zeros(shape=a.shape + (3,), dtype=\"uint8\")\n",
    "    for k, v in class_gray.items():\n",
    "        out[a == v, 0] = class_rgb[k][0]\n",
    "        out[a == v, 1] = class_rgb[k][1]\n",
    "        out[a == v, 2] = class_rgb[k][2]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hn9_yGisbYAN"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194067,
     "status": "ok",
     "timestamp": 1690291827169,
     "user": {
      "displayName": "Naoto Yokoya",
      "userId": "10610249095566174844"
     },
     "user_tz": -540
    },
    "id": "1t5R7gDKpBlu",
    "outputId": "6a0789b0-3d62-47fa-953d-1b700d006045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.81s/it, CELoss=2.52, mIoU=3.19%]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:26<00:00,  8.69s/it, CELoss=2.34, mIoU=3.53%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved!\n",
      "\n",
      "ðŸ“Œ **IoU per class (as %):**\n",
      " - Class 1: 0.00%\n",
      " - Class 2: 2.64%\n",
      " - Class 3: 0.07%\n",
      " - Class 4: 0.05%\n",
      " - Class 5: 3.54%\n",
      " - Class 6: 0.00%\n",
      " - Class 7: 0.03%\n",
      " - Class 8: 0.18%\n",
      " - Class 9: 2.44%\n",
      "\n",
      "ðŸ† **Max IoU Score: Class 5 with 3.54%**\n",
      "\n",
      "ðŸ“Œ **Epoch 1 Summary**\n",
      "ðŸ† Max Train mIoU so far: 3.19%\n",
      "ðŸ† Max Valid mIoU so far: 3.53%\n",
      "\n",
      "ðŸš€ Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.85s/it, CELoss=2.41, mIoU=3.72%]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:26<00:00,  8.70s/it, CELoss=2.27, mIoU=3.24%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ **IoU per class (as %):**\n",
      " - Class 1: 0.00%\n",
      " - Class 2: 2.52%\n",
      " - Class 3: 0.12%\n",
      " - Class 4: 0.78%\n",
      " - Class 5: 2.55%\n",
      " - Class 6: 0.01%\n",
      " - Class 7: 0.05%\n",
      " - Class 8: 0.17%\n",
      " - Class 9: 1.73%\n",
      "\n",
      "ðŸ† **Max IoU Score: Class 5 with 2.55%**\n",
      "\n",
      "ðŸ“Œ **Epoch 2 Summary**\n",
      "ðŸ† Max Train mIoU so far: 3.72%\n",
      "ðŸ† Max Valid mIoU so far: 3.24%\n",
      "\n",
      "ðŸš€ Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.85s/it, CELoss=2.32, mIoU=4.04%]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:26<00:00,  8.70s/it, CELoss=2.19, mIoU=4.46%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved!\n",
      "\n",
      "ðŸ“Œ **IoU per class (as %):**\n",
      " - Class 1: 0.00%\n",
      " - Class 2: 2.20%\n",
      " - Class 3: 0.09%\n",
      " - Class 4: 0.62%\n",
      " - Class 5: 4.08%\n",
      " - Class 6: 0.00%\n",
      " - Class 7: 0.00%\n",
      " - Class 8: 0.06%\n",
      " - Class 9: 3.76%\n",
      "\n",
      "ðŸ† **Max IoU Score: Class 5 with 4.08%**\n",
      "\n",
      "ðŸ“Œ **Epoch 3 Summary**\n",
      "ðŸ† Max Train mIoU so far: 4.04%\n",
      "ðŸ† Max Valid mIoU so far: 4.46%\n",
      "\n",
      "ðŸš€ Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.86s/it, CELoss=2.25, mIoU=4.31%]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:26<00:00,  8.69s/it, CELoss=2.19, mIoU=4.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved!\n",
      "\n",
      "ðŸ“Œ **IoU per class (as %):**\n",
      " - Class 1: 0.00%\n",
      " - Class 2: 1.47%\n",
      " - Class 3: 0.11%\n",
      " - Class 4: 0.24%\n",
      " - Class 5: 4.55%\n",
      " - Class 6: 0.00%\n",
      " - Class 7: 0.00%\n",
      " - Class 8: 0.03%\n",
      " - Class 9: 5.45%\n",
      "\n",
      "ðŸ† **Max IoU Score: Class 9 with 5.45%**\n",
      "\n",
      "ðŸ“Œ **Epoch 4 Summary**\n",
      "ðŸ† Max Train mIoU so far: 4.31%\n",
      "ðŸ† Max Valid mIoU so far: 4.85%\n",
      "\n",
      "ðŸš€ Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.84s/it, CELoss=2.19, mIoU=4.85%]\n",
      "Valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:26<00:00,  8.69s/it, CELoss=2.08, mIoU=5.70%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved!\n",
      "\n",
      "ðŸ“Œ **IoU per class (as %):**\n",
      " - Class 1: 0.00%\n",
      " - Class 2: 1.72%\n",
      " - Class 3: 0.12%\n",
      " - Class 4: 0.29%\n",
      " - Class 5: 4.93%\n",
      " - Class 6: 0.00%\n",
      " - Class 7: 0.00%\n",
      " - Class 8: 0.03%\n",
      " - Class 9: 6.66%\n",
      "\n",
      "ðŸ† **Max IoU Score: Class 9 with 6.66%**\n",
      "\n",
      "ðŸ“Œ **Epoch 5 Summary**\n",
      "ðŸ† Max Train mIoU so far: 4.85%\n",
      "ðŸ† Max Valid mIoU so far: 5.70%\n",
      "\n",
      "â³ Processing time: 227.48291087150574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Training\n",
    "start = time.time()\n",
    "\n",
    "max_score = 0\n",
    "train_hist = []\n",
    "valid_hist = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"\\nðŸš€ Epoch: {epoch + 1}\")\n",
    "\n",
    "    logs_train, train_iou_per_class = source.runner.train_epoch(\n",
    "        model=network,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        metric=metric,\n",
    "        dataloader=train_loader,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    logs_valid, valid_iou_per_class = source.runner.valid_epoch(\n",
    "        model=network,\n",
    "        criterion=criterion,\n",
    "        metric=metric,\n",
    "        dataloader=valid_loader,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    train_hist.append(logs_train)\n",
    "    valid_hist.append(logs_valid)\n",
    "\n",
    "    score = logs_valid[\"mIoU\"]\n",
    "\n",
    "    if max_score < score:\n",
    "        max_score = score\n",
    "        torch.save(network.state_dict(), os.path.join(WEIGHT_DIR, f\"{network_fout}.pth\"))\n",
    "        print(\"âœ… Model saved!\")\n",
    "\n",
    "    # Print per-class IoU\n",
    "    print(\"\\nðŸ“Œ **IoU per class (as %):**\")\n",
    "    for i, class_iou in enumerate(valid_iou_per_class, start=0):\n",
    "        print(f\" - Class {i}: {class_iou * 100:.2f}%\")\n",
    "\n",
    "    # Find the best-performing class\n",
    "    best_class = np.nanargmax(valid_iou_per_class) + 1\n",
    "    best_class_iou = valid_iou_per_class[best_class - 1] * 100\n",
    "    print(f\"\\nðŸ† **Max IoU Score: Class {best_class} with {best_class_iou:.2f}%**\")\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"\\nðŸ“Œ **Epoch {epoch + 1} Summary**\")\n",
    "    print(f\"ðŸ† Max Train mIoU so far: {logs_train['mIoU'] * 100:.2f}%\")\n",
    "    print(f\"ðŸ† Max Valid mIoU so far: {logs_valid['mIoU'] * 100:.2f}%\")\n",
    "\n",
    "end = time.time()\n",
    "print(\"\\nâ³ Processing time:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONWiNQMWAHP4"
   },
   "source": [
    "### Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9502,
     "status": "ok",
     "timestamp": 1690293506779,
     "user": {
      "displayName": "Naoto Yokoya",
      "userId": "10610249095566174844"
     },
     "user_tz": -540
    },
    "id": "s0slbVQcmQlp",
    "outputId": "133da56c-c059-4abf-b290-8b5401ab62ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: 0.5042271614074707\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# load network\n",
    "network.load_state_dict(torch.load(os.path.join(WEIGHT_DIR, f\"{network_fout}.pth\")))\n",
    "network.to(device).eval()\n",
    "\n",
    "test_pths = glob.glob(TEST_DIR+\"/*.tif\")\n",
    "#testset = source.dataset.Dataset(test_pths, classes=classes, train=False)\n",
    "\n",
    "for fn_img in test_pths:\n",
    "  img = source.dataset.load_multiband(fn_img)\n",
    "  h, w = img.shape[:2]\n",
    "  power = math.ceil(np.log2(h) / np.log2(2))\n",
    "  shape = (2 ** power, 2 ** power)\n",
    "  img = cv2.resize(img, shape)\n",
    "\n",
    "  # test time augmentation\n",
    "  imgs = []\n",
    "  imgs.append(img.copy())\n",
    "  imgs.append(img[:, ::-1, :].copy())\n",
    "  imgs.append(img[::-1, :, :].copy())\n",
    "  imgs.append(img[::-1, ::-1, :].copy())\n",
    "\n",
    "  input = torch.cat([TF.to_tensor(x).unsqueeze(0) for x in imgs], dim=0).float().to(device)\n",
    "\n",
    "  pred = []\n",
    "  with torch.no_grad():\n",
    "      msk = network(input)\n",
    "      msk = torch.softmax(msk[:, :, ...], dim=1)\n",
    "      msk = msk.cpu().numpy()\n",
    "      pred = (msk[0, :, :, :] + msk[1, :, :, ::-1] + msk[2, :, ::-1, :] + msk[3, :, ::-1, ::-1])/4\n",
    "  pred = pred.argmax(axis=0).astype(\"uint8\")\n",
    "  size = pred.shape[0:]\n",
    "  y_pr = cv2.resize(pred, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "  # save image as png\n",
    "  filename = os.path.splitext(os.path.basename(fn_img))[0]\n",
    "  y_pr_rgb = label2rgb(y_pr)\n",
    "  Image.fromarray(y_pr_rgb).save(os.path.join(OUT_DIR, filename+'test.png'))\n",
    "\n",
    "end = time.time()\n",
    "print('Processing time:',end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3I0hKRyHMl3"
   },
   "source": [
    "### Testing a model for a large Geotiff image\n",
    "\n",
    "A sample image is provided by the Geospatial Information Authority of Japan at https://cyberjapandata.gsi.go.jp/xyz/seamlessphoto/{z}/{x}/{y}.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88911,
     "status": "ok",
     "timestamp": 1690293670303,
     "user": {
      "displayName": "Naoto Yokoya",
      "userId": "10610249095566174844"
     },
     "user_tz": -540
    },
    "id": "WguTdAFqHWAe",
    "outputId": "f33e8f67-8953-4fca-bc11-11b670003234"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: 218.02295088768005\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# load network\n",
    "network.load_state_dict(torch.load(os.path.join(WEIGHT_DIR, f\"{network_fout}.pth\")))\n",
    "network.to(device).eval()\n",
    "\n",
    "# process large Geotiff image\n",
    "img0 = source.dataset.load_multiband(test_large)\n",
    "\n",
    "# get crs and transform\n",
    "crs, trans = source.dataset.get_crs(test_large)\n",
    "\n",
    "if img0.shape[2] > 3:\n",
    "    img0 = img0[:,:,[0,1,2]]\n",
    "height = img0.shape[0]\n",
    "width = img0.shape[1]\n",
    "band = img0.shape[2]\n",
    "\n",
    "patch_size = 512\n",
    "stride = 256\n",
    "C = int(np.ceil( (width - patch_size) / stride ) + 1)\n",
    "R = int(np.ceil( (height - patch_size) / stride ) + 1)\n",
    "\n",
    "# weight matrix B for avoiding boundaries of patches\n",
    "if patch_size > stride:\n",
    "    w = patch_size\n",
    "    s1 = stride\n",
    "    s2 = w - s1\n",
    "    d = 1/(1+s2)\n",
    "    B1 = np.ones((w,w))\n",
    "    B1[:,s1::] = np.dot(np.ones((w,1)),(-np.arange(1,s2+1)*d+1).reshape(1,s2))\n",
    "    B2 = np.flip(B1)\n",
    "    B3 = B1.T\n",
    "    B4 = np.flip(B3)\n",
    "    B = B1*B2*B3*B4\n",
    "else:\n",
    "    B = np.ones((w,w))\n",
    "\n",
    "img1 = np.zeros((patch_size+stride*(R-1), patch_size+stride*(C-1),3))\n",
    "img1[0:height,0:width,:] = img0.copy()\n",
    "\n",
    "pred_all = np.zeros((9,patch_size+stride*(R-1), patch_size+stride*(C-1)))\n",
    "weight = np.zeros((patch_size+stride*(R-1), patch_size+stride*(C-1)))\n",
    "\n",
    "for r in range(R):\n",
    "    for c in range(C):\n",
    "        img = img1[r*stride:r*stride+patch_size,c*stride:c*stride+patch_size,:].copy().astype(np.float32)/255\n",
    "        imgs = []\n",
    "        imgs.append(img.copy())\n",
    "        imgs.append(img[:, ::-1, :].copy())\n",
    "        imgs.append(img[::-1, :, :].copy())\n",
    "        imgs.append(img[::-1, ::-1, :].copy())\n",
    "\n",
    "        input = torch.cat([TF.to_tensor(x).unsqueeze(0) for x in imgs], dim=0).float().to(device)\n",
    "\n",
    "        pred = []\n",
    "        with torch.no_grad():\n",
    "            msk = network(input)\n",
    "            msk = torch.softmax(msk[:, :, ...], dim=1)\n",
    "            msk = msk.cpu().numpy()\n",
    "\n",
    "            pred = (msk[0, :, :, :] + msk[1, :, :, ::-1] + msk[2, :, ::-1, :] + msk[3, :, ::-1, ::-1])/4\n",
    "\n",
    "        pred_all[:,r*stride:r*stride+patch_size,c*stride:c*stride+patch_size] += pred.copy()*B\n",
    "        weight[r*stride:r*stride+patch_size,c*stride:c*stride+patch_size] += B\n",
    "\n",
    "for b in range(9):\n",
    "    pred_all[b,:,:] = pred_all[b,:,:]/weight\n",
    "    if b == 0:\n",
    "        pred_all[b,:,:] = 0\n",
    "\n",
    "pred_all = pred_all.argmax(axis=0).astype(\"uint8\")\n",
    "\n",
    "filename = os.path.splitext(os.path.basename(test_large))[0]\n",
    "pr_rgb = label2rgb(pred_all)\n",
    "Image.fromarray(pr_rgb[0:height,0:width,:]).save(os.path.join(OUT_DIR, filename+'_pr.png'))\n",
    "\n",
    "# save geotiff\n",
    "pr_rgb = np.transpose(pr_rgb[0:height,0:width,:], (2,0,1))\n",
    "source.dataset.save_img(os.path.join(OUT_DIR, filename+'_pr.tif'),pr_rgb,crs,trans)\n",
    "\n",
    "end = time.time()\n",
    "print('Processing time:',end - start)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
